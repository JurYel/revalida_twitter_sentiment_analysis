{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e556ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext import data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "TEXT = data.Field(tokenize='spacy',\n",
    "                 tokenizer_language='en_core_web_sm')\n",
    "LABEL = data.LabelField()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc53fcb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arirang simply kpop kim hyung jun cross ha yeo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>read politico article donald trump running mat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>type bazura project google image image photo d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fast lerner subpoena tech guy work hillary pri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sony reward app like lot female singer non ret...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49670</th>\n",
       "      <td>sleep think fuck jordan answer phone tomorrow ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49671</th>\n",
       "      <td>yoga shannon tomorrow morning work day start u...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49672</th>\n",
       "      <td>bring dunkin iced coffee tomorrow hero</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49673</th>\n",
       "      <td>currently holiday portugal come home tomorrow ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49674</th>\n",
       "      <td>ladykiller saturday aternoon</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49675 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 message  label\n",
       "0      arirang simply kpop kim hyung jun cross ha yeo...      1\n",
       "1      read politico article donald trump running mat...      1\n",
       "2      type bazura project google image image photo d...      1\n",
       "3      fast lerner subpoena tech guy work hillary pri...      1\n",
       "4      sony reward app like lot female singer non ret...      0\n",
       "...                                                  ...    ...\n",
       "49670  sleep think fuck jordan answer phone tomorrow ...      0\n",
       "49671  yoga shannon tomorrow morning work day start u...      1\n",
       "49672             bring dunkin iced coffee tomorrow hero      1\n",
       "49673  currently holiday portugal come home tomorrow ...      1\n",
       "49674                       ladykiller saturday aternoon      1\n",
       "\n",
       "[49675 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_dir = \"data/twitter_dataset/tweets_train_tokens.csv\"\n",
    "\n",
    "tweets_df = pd.read_csv(train_x_dir)\n",
    "tweets_df['label'] = tweets_df['label'].astype('int')\n",
    "\n",
    "tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3abec4a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>beyonce pearl jam ed sheeran coldplay play glo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10770</th>\n",
       "      <td>rt kiss beyonce pearl bedd night wass wife</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 message  label\n",
       "9994   beyonce pearl jam ed sheeran coldplay play glo...      2\n",
       "10770         rt kiss beyonce pearl bedd night wass wife      2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.dropna(inplace=True)\n",
    "tweets_df.drop_duplicates(inplace=True)\n",
    "tweets_df.loc[tweets_df['message'].str.contains('beyonce pearl')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21e2d413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.447492\n",
       "2    0.396289\n",
       "0    0.156219\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df['label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec167665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arirang simply kpop kim hyung jun cross ha yeo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>read politico article donald trump running mat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>type bazura project google image image photo d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fast lerner subpoena tech guy work hillary pri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sony reward app like lot female singer non ret...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66406</th>\n",
       "      <td>meet friday shakedown nicki probably</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66407</th>\n",
       "      <td>omfgomfgomfgomfg black dahlia murder machine h...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66408</th>\n",
       "      <td>buy twilight bc lose old copy uncool lame enjo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66409</th>\n",
       "      <td>season longmire premiere tomorrow september ne...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66410</th>\n",
       "      <td>coach like gonzaga chance mon oct pst count za...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66411 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 message  label\n",
       "0      arirang simply kpop kim hyung jun cross ha yeo...      1\n",
       "1      read politico article donald trump running mat...      1\n",
       "2      type bazura project google image image photo d...      1\n",
       "3      fast lerner subpoena tech guy work hillary pri...      1\n",
       "4      sony reward app like lot female singer non ret...      0\n",
       "...                                                  ...    ...\n",
       "66406               meet friday shakedown nicki probably      2\n",
       "66407  omfgomfgomfgomfg black dahlia murder machine h...      2\n",
       "66408  buy twilight bc lose old copy uncool lame enjo...      2\n",
       "66409  season longmire premiere tomorrow september ne...      2\n",
       "66410  coach like gonzaga chance mon oct pst count za...      2\n",
       "\n",
       "[66411 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "oversampler = RandomOverSampler()\n",
    "X_train_balanced, y_train_balanced = oversampler.fit_resample(np.array(tweets_df['message']).reshape(-1, 1),\n",
    "                                                             np.array(tweets_df['label']).reshape(-1, 1))\n",
    "tweets_df_balanced = pd.DataFrame(list(zip([x[0] for x in X_train_balanced], y_train_balanced)), columns=['message', 'label'])\n",
    "tweets_df_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5ba6f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    15970\n",
       "0    15951\n",
       "2    15894\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tweets_df_balanced['message'], tweets_df_balanced['label'], test_size=0.2, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\n",
    "\n",
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "test_data = pd.concat([X_test, y_test], axis=1)\n",
    "valid_data = pd.concat([X_valid, y_valid], axis=1)\n",
    "\n",
    "train_data['label'].value_counts()\n",
    "# X_train.shape, X_test.shape, X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0ade371",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv('data/twitter_dataset/split/train_tweets.csv', index=False)\n",
    "test_data.to_csv('data/twitter_dataset/split/test_tweets.csv', index=False)\n",
    "valid_data.to_csv('data/twitter_dataset/split/valid_tweets.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b74b438f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of training examples: 47815\n",
      "Length of testing examples: 13283\n",
      "Length of validation examples: 5313\n"
     ]
    }
   ],
   "source": [
    "train_data, valid_data, test_data = data.TabularDataset.splits(\n",
    "                path = 'data/twitter_dataset/split/',\n",
    "                train = 'train_tweets.csv',\n",
    "                test = 'test_tweets.csv',\n",
    "                validation = 'valid_tweets.csv',\n",
    "                format='csv',\n",
    "                skip_header=True,\n",
    "                fields = [('message', TEXT), ('label', LABEL)]\n",
    "            )\n",
    "\n",
    "print(f'Length of training examples: {len(train_data)}')\n",
    "print(f'Length of testing examples: {len(test_data)}')\n",
    "print(f'Length of validation examples: {len(valid_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1391c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'message': ['fall', 'sick', 'day', 'eid', 'miss', 'fun', 'joy', 'eid', 'sad'], 'label': '0'}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2218da95",
   "metadata": {},
   "source": [
    "The following builds the vocabulary, only keeping the most common max_size tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "141e22a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 25_000\n",
    "\n",
    "TEXT.build_vocab(train_data, max_size = MAX_VOCAB_SIZE)\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91aa9240",
   "metadata": {},
   "source": [
    "Why do we only build the vocabulary on the training set? When testing any machine learning system you do not want to look at the test set in any way. We do not include the validation set as we want it to reflect the test set as much as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71ae0bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "358fca21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 25002\n",
      "Unique tokens in LABEL vocabulary: 3\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
    "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5ab45c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None, {'1': 0, '0': 1, '2': 2})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABEL.vocab.stoi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356d10a1",
   "metadata": {},
   "source": [
    "Why is the vocab size 25002 and not 25000? One of the addition tokens is the `<unk>` token and the other is a `<pad>` token.\n",
    "<br>\n",
    "\n",
    "When we feed sentences into our model, we feed a *batch* of them at a time, i.e. more than one at a time, and all sentences in the batch need to be the same size. Thus, to ensure each sentence in the batch is the same size, any shorter than the longest within the batch are padded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffe096f",
   "metadata": {},
   "source": [
    "We can also view the most common words in the vocabulary and their frequencies.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e37aa300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('tomorrow', 7570), ('day', 4353), ('like', 3079), ('night', 2987), ('friday', 2796), ('time', 2762), ('sunday', 2677), ('good', 2466), ('come', 2406), ('watch', 2192), ('saturday', 2089), ('game', 1973), ('amp', 1911), ('want', 1911), ('think', 1880), ('monday', 1824), ('know', 1815), ('new', 1791), ('today', 1654), ('play', 1501)]\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.freqs.most_common(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c207c619",
   "metadata": {},
   "source": [
    "We can also see the vocabulary directly using either the `stoi` (string to int) or `itos` (int to string) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e473099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<unk>', '<pad>', 'tomorrow', 'day', 'like', 'night', 'friday', 'time', 'sunday', 'good']\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.itos[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56913ce2",
   "metadata": {},
   "source": [
    "We can also check the labels, ensuring 0 is for negative and 1 is for positive.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3bd1d169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(None, {'1': 0, '0': 1, '2': 2})\n"
     ]
    }
   ],
   "source": [
    "print(LABEL.vocab.stoi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbe761a",
   "metadata": {},
   "source": [
    "The final step of preparing the data is creating the iterators. We iterate over these in the training/evaluation loop, and they return a batch of examples (indexed and converted into tensors) at each iteration.\n",
    "<br>\n",
    "\n",
    "We'll use a `BucketIterator` which is a special type of iterator that will return a batch of examples where each example is of a similar length, minimizing the amount of padding per example.\n",
    "<br>\n",
    "\n",
    "We also want to place the tensors returned by the iterator on the GPU (if you're using one). PyTorch handles this using `torch.device`, we then pass this device to the iterator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a255053d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 96\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "                            (train_data, valid_data, test_data),\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            device=device,\n",
    "                            sort_key = lambda x: len(x.message),\n",
    "                            sort_within_batch=True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ce15c5",
   "metadata": {},
   "source": [
    "## Build the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784e4430",
   "metadata": {},
   "source": [
    "The next stage is building the model that we'll eventually train and evaluate.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "49be6af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        \n",
    "        self.rnn = nn.GRU(embedding_dim, hidden_dim)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        self.softmax = nn.Softmax()\n",
    "        \n",
    "    def forward(self, text):\n",
    "        \n",
    "        # text = [sent_len, batch_size]\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "        # embedded = [sent_lence, batch_size, emb_dim]\n",
    "        \n",
    "        output, hidden = self.rnn(embedded)\n",
    "        # output = [sent_len, batch_size, hidden_dim]\n",
    "        # hidden = [1, batch_size, hidden_dim]\n",
    "        \n",
    "        assert torch.equal(output[-1,:, :], hidden.squeeze(0))\n",
    "\n",
    "#         output = self.fc(hidden.squeeze(0))\n",
    "        \n",
    "        return self.fc(hidden.squeeze(0))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824b9926",
   "metadata": {},
   "source": [
    "We now create an instance of our RNN class.\n",
    "<br>\n",
    "\n",
    "The input dimension is the dimension of the one-hot vectors, which is equal to the vocabulary size.\n",
    "<br>\n",
    "\n",
    "The embedding dimension is the size of the dense word vectors. This is usually around 50-250 dimensions, but depends on the size of the vocabulary.\n",
    "<br>\n",
    "\n",
    "The hidden dimension is the size of the hidden states. This is usually around 100-500 dimensions, but also depends on factors such as on the vocabulary size, the size of the dense vectors and the complexity of the task.\n",
    "<br>\n",
    "\n",
    "The output dimension is usually the number of classes, however in the case of only 2 classes the output value is between 0 and 1 and thus can be 1-dimensional, i.e. a single scalar real number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cf9ff8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 3\n",
    "\n",
    "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7592187c",
   "metadata": {},
   "source": [
    "Let's also create a function that will tell us how many trainable parameters our model has so we can compare the number of parameters across different models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1bd4557c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 2,775,915 trainable parameters.\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03019787",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802c39b5",
   "metadata": {},
   "source": [
    "Now we'll set up the training and then train the model.\n",
    "<br>\n",
    "\n",
    "First, we'll create an optimizer. This is the algorithm we use to update the parameters of the module. Here, we'll use *stochastic gradient descent* (SGD). The first argument is the parameters will be updated by the optimizer, the second is the learning rate, i.e. how much we'll change the parameters by when we do a parameter update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "de541de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb337e31",
   "metadata": {},
   "source": [
    "Next, we'll define our loss function. In PyTorch this is commonly called a criterion.\n",
    "<br>\n",
    "\n",
    "The loss function here is *cross entropy loss*.\n",
    "<br>\n",
    "\n",
    "Our model currently outputs an unbound real number. As our labels are either 0, 1, or 2, we want to restrict the predictions to a number between 0, 1, and 2. We do this using the *softmax* function.\n",
    "<br>\n",
    "\n",
    "We then use this this bound scalar to calculate the loss using cross entropy.\n",
    "<br>\n",
    "\n",
    "The `CrossEntropyLoss` criterion carries out both the softmax and the cross entropy steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "38244148",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d87ce5a",
   "metadata": {},
   "source": [
    "Using `.to`, we can place the model and the criterion on the GPU (if we have one).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6fcb11d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e331abf",
   "metadata": {},
   "source": [
    "Our criterion function calculates the loss, however we have to write our function to calculate the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "adcd7a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_accuracy(y_pred, y_true):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to calculate accuracy\n",
    "    -> param y_true: list of true values\n",
    "    -> param y_pred: list of predicted values\n",
    "    -> return: accuracy score\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Intitializing variable to store count of correctly predicted classes\n",
    "    correct_predictions = 0\n",
    "#     print(torch.round(torch.argmax(torch.softmax(y_pred))))\n",
    "#     print(y_pred)\n",
    "#     print(torch.round(torch.sigmoid(y_pred)))\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        yp = torch.argmax(yp)\n",
    "        if yt == yp:\n",
    "            \n",
    "            correct_predictions += 1\n",
    "    \n",
    "    #returns accuracy\n",
    "    return correct_predictions / len(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a193aa90",
   "metadata": {},
   "source": [
    "**Define Train Function** <br>\n",
    "The train function iterates over all examples, one batch at a time.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "55d1f288",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    loop = tqdm(iterator)\n",
    "    for batch in loop:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(batch.message).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch.label)\n",
    "        \n",
    "        acc = multiclass_accuracy(predictions, batch.label)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += (predictions.argmax(1) == batch.label).sum().item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4ea6fc",
   "metadata": {},
   "source": [
    "`evaluate` is similar to `train`, with a few modifications as you don't want to update the parameters when evaluating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a0197e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "#     loop = tqdm(iterator)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for batch in iterator:\n",
    "            \n",
    "            predictions = model(batch.message).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, batch.label)\n",
    "            \n",
    "            acc = multiclass_accuracy(predictions, batch.label)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc\n",
    "            \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae298943",
   "metadata": {},
   "source": [
    "We'll also create a function to tell us how long an epoch takes to compare training times between models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d4b5dc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    \n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8a0333",
   "metadata": {},
   "source": [
    "We then train the model through multiple epochs, an epoch being a complete pass through all examples in the training and validation sets.\n",
    "<br>\n",
    "\n",
    "At each epoch, if the validation loss is the best we have seen so far, we'll save the parameters of the model and then after training has finished we'll use that model on the test set.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f88fbb21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 499/499 [00:26<00:00, 18.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 1.102 | Train Acc: 3325.45%\n",
      "\t Val. Loss: 1.101 |  Val. Acc: 34.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 499/499 [00:22<00:00, 22.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Epoch Time: 0m 23s\n",
      "\tTrain Loss: 1.099 | Train Acc: 3397.60%\n",
      "\t Val. Loss: 1.097 |  Val. Acc: 35.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 499/499 [00:22<00:00, 22.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Epoch Time: 0m 23s\n",
      "\tTrain Loss: 1.097 | Train Acc: 3449.70%\n",
      "\t Val. Loss: 1.094 |  Val. Acc: 37.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 499/499 [00:23<00:00, 21.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Epoch Time: 0m 23s\n",
      "\tTrain Loss: 1.095 | Train Acc: 3491.98%\n",
      "\t Val. Loss: 1.092 |  Val. Acc: 37.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 499/499 [00:23<00:00, 21.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Epoch Time: 0m 23s\n",
      "\tTrain Loss: 1.094 | Train Acc: 3541.88%\n",
      "\t Val. Loss: 1.090 |  Val. Acc: 37.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 499/499 [00:22<00:00, 21.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06 | Epoch Time: 0m 23s\n",
      "\tTrain Loss: 1.092 | Train Acc: 3587.17%\n",
      "\t Val. Loss: 1.088 |  Val. Acc: 38.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 499/499 [00:23<00:00, 21.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07 | Epoch Time: 0m 24s\n",
      "\tTrain Loss: 1.090 | Train Acc: 3638.28%\n",
      "\t Val. Loss: 1.086 |  Val. Acc: 38.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 499/499 [00:23<00:00, 21.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08 | Epoch Time: 0m 24s\n",
      "\tTrain Loss: 1.089 | Train Acc: 3660.32%\n",
      "\t Val. Loss: 1.084 |  Val. Acc: 39.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 499/499 [00:22<00:00, 21.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09 | Epoch Time: 0m 23s\n",
      "\tTrain Loss: 1.088 | Train Acc: 3694.19%\n",
      "\t Val. Loss: 1.083 |  Val. Acc: 39.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 499/499 [00:26<00:00, 19.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 1.087 | Train Acc: 3709.62%\n",
      "\t Val. Loss: 1.081 |  Val. Acc: 40.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 499/499 [00:27<00:00, 18.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 | Epoch Time: 0m 28s\n",
      "\tTrain Loss: 1.086 | Train Acc: 3734.67%\n",
      "\t Val. Loss: 1.080 |  Val. Acc: 40.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 499/499 [00:26<00:00, 19.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 1.085 | Train Acc: 3743.49%\n",
      "\t Val. Loss: 1.079 |  Val. Acc: 40.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 499/499 [00:25<00:00, 19.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 | Epoch Time: 0m 26s\n",
      "\tTrain Loss: 1.084 | Train Acc: 3760.92%\n",
      "\t Val. Loss: 1.078 |  Val. Acc: 40.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 499/499 [00:22<00:00, 22.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 | Epoch Time: 0m 23s\n",
      "\tTrain Loss: 1.083 | Train Acc: 3785.77%\n",
      "\t Val. Loss: 1.077 |  Val. Acc: 40.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 499/499 [00:22<00:00, 22.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 | Epoch Time: 0m 22s\n",
      "\tTrain Loss: 1.083 | Train Acc: 3802.61%\n",
      "\t Val. Loss: 1.076 |  Val. Acc: 40.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 499/499 [00:22<00:00, 22.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 | Epoch Time: 0m 23s\n",
      "\tTrain Loss: 1.081 | Train Acc: 3815.63%\n",
      "\t Val. Loss: 1.075 |  Val. Acc: 40.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 499/499 [00:22<00:00, 22.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 | Epoch Time: 0m 23s\n",
      "\tTrain Loss: 1.081 | Train Acc: 3828.86%\n",
      "\t Val. Loss: 1.074 |  Val. Acc: 40.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 499/499 [00:22<00:00, 22.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 | Epoch Time: 0m 23s\n",
      "\tTrain Loss: 1.080 | Train Acc: 3840.68%\n",
      "\t Val. Loss: 1.073 |  Val. Acc: 41.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 499/499 [00:23<00:00, 21.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 | Epoch Time: 0m 23s\n",
      "\tTrain Loss: 1.079 | Train Acc: 3857.72%\n",
      "\t Val. Loss: 1.073 |  Val. Acc: 41.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 499/499 [00:22<00:00, 21.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 | Epoch Time: 0m 23s\n",
      "\tTrain Loss: 1.079 | Train Acc: 3871.74%\n",
      "\t Val. Loss: 1.072 |  Val. Acc: 41.17%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 20\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "\n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'models/rnn-model.pt')\n",
    "        \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4228ce",
   "metadata": {},
   "source": [
    "You may have noticed the loss is not really decreasing and the accuracy is poor. This is due to several issues with the model which will be improved later on.\n",
    "<br>\n",
    "\n",
    "Finally, the metric we actually care about, the test loss and accuracy, which we get from our parameters that gave us the best validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9bb4d5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.074 | Test Acc: 40.20%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('models/rnn-model.pt'))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1350474",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de532cf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7fdb79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b74da1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
