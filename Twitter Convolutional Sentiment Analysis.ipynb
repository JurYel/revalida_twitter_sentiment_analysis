{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f50bed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext import data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "TEXT = data.Field(tokenize='spacy',\n",
    "                 tokenizer_language='en_core_web_sm',\n",
    "                 include_lengths=True)\n",
    "LABEL = data.LabelField(dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05b64198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arirang simply kpop kim hyung jun cross ha yeo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>read politico article donald trump running mat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>type bazura project google image image photo d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fast lerner subpoena tech guy work hillary pri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sony reward app like lot female singer non ret...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49670</th>\n",
       "      <td>sleep think fuck jordan answer phone tomorrow ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49671</th>\n",
       "      <td>yoga shannon tomorrow morning work day start u...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49672</th>\n",
       "      <td>bring dunkin iced coffee tomorrow hero</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49673</th>\n",
       "      <td>currently holiday portugal come home tomorrow ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49674</th>\n",
       "      <td>ladykiller saturday aternoon</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49675 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 message  label\n",
       "0      arirang simply kpop kim hyung jun cross ha yeo...      1\n",
       "1      read politico article donald trump running mat...      1\n",
       "2      type bazura project google image image photo d...      1\n",
       "3      fast lerner subpoena tech guy work hillary pri...      1\n",
       "4      sony reward app like lot female singer non ret...      0\n",
       "...                                                  ...    ...\n",
       "49670  sleep think fuck jordan answer phone tomorrow ...      0\n",
       "49671  yoga shannon tomorrow morning work day start u...      1\n",
       "49672             bring dunkin iced coffee tomorrow hero      1\n",
       "49673  currently holiday portugal come home tomorrow ...      1\n",
       "49674                       ladykiller saturday aternoon      1\n",
       "\n",
       "[49675 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_dir = \"data/twitter_dataset/tweets_train_tokens.csv\"\n",
    "\n",
    "tweets_df = pd.read_csv(train_x_dir)\n",
    "tweets_df['label'] = tweets_df['label'].astype('int')\n",
    "\n",
    "tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87bdfc74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>beyonce pearl jam ed sheeran coldplay play glo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10770</th>\n",
       "      <td>rt kiss beyonce pearl bedd night wass wife</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 message  label\n",
       "9994   beyonce pearl jam ed sheeran coldplay play glo...      2\n",
       "10770         rt kiss beyonce pearl bedd night wass wife      2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.dropna(inplace=True)\n",
    "tweets_df.drop_duplicates(inplace=True)\n",
    "tweets_df.loc[tweets_df['message'].str.contains('beyonce pearl')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "214f4480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.447492\n",
       "2    0.396289\n",
       "0    0.156219\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df['label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a93f34",
   "metadata": {},
   "source": [
    "**Split data to train, test,validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cd75943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    15968\n",
       "2    14042\n",
       "0     5607\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tweets_df['message'], tweets_df['label'], test_size=0.2, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\n",
    "\n",
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "test_data = pd.concat([X_test, y_test], axis=1)\n",
    "valid_data = pd.concat([X_valid, y_valid], axis=1)\n",
    "\n",
    "train_data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10f1aa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv(\"train_tweets.csv\", index=False)\n",
    "test_data.to_csv(\"test_tweets.csv\", index=False)\n",
    "valid_data.to_csv(\"valid_tweets.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131ebd60",
   "metadata": {},
   "source": [
    "## Load data as TabularDataset from Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b796a51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of training examples: 35617\n",
      "Length of testing examples: 9894\n",
      "Length of validation examples: 3958\n"
     ]
    }
   ],
   "source": [
    "train_data, valid_data, test_data = data.TabularDataset.splits(\n",
    "                            path = 'data/twitter_dataset/split/',\n",
    "                            train = 'train_tweets.csv',\n",
    "                            test = 'test_tweets.csv',\n",
    "                            validation='valid_tweets.csv',\n",
    "                            format='csv',\n",
    "                            skip_header=True,\n",
    "                            fields=[('message', TEXT), ('label', LABEL)]\n",
    "                        )\n",
    "\n",
    "print(f'Length of training examples: {len(train_data)}')\n",
    "print(f'Length of testing examples: {len(test_data)}')\n",
    "print(f'Length of validation examples: {len(valid_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8dc14c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'message': ['low', 'key', 'want', 'drop', 'justin', 'school', 'tomorrow', 'bump', 'taylor', 'swift', 'embarrass'], 'label': '1'}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f7736c",
   "metadata": {},
   "source": [
    "## Create BucketIterator for the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "425110ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 40_000\n",
    "\n",
    "TEXT.build_vocab(train_data, \n",
    "                 max_size = MAX_VOCAB_SIZE,\n",
    "                 vectors=\"glove.6B.100d\",\n",
    "                 unk_init=torch.Tensor.normal_)\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10c34ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 29703\n",
      "Unique tokens in LABEL vocabulary: 3\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
    "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "061e2f08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None, {'1': 0, '2': 1, '0': 2})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABEL.vocab.stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2531c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('tomorrow', 5749), ('day', 3357), ('night', 2372), ('friday', 2213), ('sunday', 2104), ('time', 2084), ('like', 2046), ('good', 2000), ('come', 1847), ('watch', 1701), ('saturday', 1652), ('game', 1577), ('new', 1458), ('monday', 1397), ('want', 1384), ('amp', 1379), ('think', 1340), ('know', 1328), ('today', 1201), ('play', 1156)]\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.freqs.most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3b4cfd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<unk>', '<pad>', 'tomorrow', 'day', 'night', 'friday', 'sunday', 'time', 'like', 'good']\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.itos[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e892eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "                                    (train_data, valid_data, test_data),\n",
    "                                    batch_size=BATCH_SIZE,\n",
    "                                    device=device,\n",
    "                                    sort_key = lambda x: len(x.message),\n",
    "                                    sort_within_batch=True\n",
    "                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b279a83",
   "metadata": {},
   "source": [
    "## Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "846f4b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes,\n",
    "                output_dim, dropout, pad_idx):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        \n",
    "        self.conv_0 = nn.Conv2d(in_channels = 1,\n",
    "                               out_channels = n_filters,\n",
    "                               kernel_size = (filter_sizes[0], embedding_dim))\n",
    "        \n",
    "        self.conv_1 = nn.Conv2d(in_channels = 1,\n",
    "                               out_channels = n_filters,\n",
    "                               kernel_size = (filter_sizes[1], embedding_dim))\n",
    "        \n",
    "        self.conv_2 = nn.Conv2d(in_channels = 1,\n",
    "                               out_channels = n_filters,\n",
    "                               kernel_size = (filter_sizes[2], embedding_dim))\n",
    "        \n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        \n",
    "        # text = [batch size, sentence length]\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "        \n",
    "        # embedded = [batch_sze, sentence_length, emb_dim]\n",
    "        \n",
    "        embeddded = embedded.unsqueeze(1)\n",
    "        \n",
    "        # embedded = [batch_size, 1, sentence_length, emb_dim]\n",
    "        \n",
    "        conved_0 = F.relu(self.conv_0(embedded).squeeze(3))\n",
    "        conved_1 = F.relu(self.conv_1(embedded).squeeze(3))\n",
    "        conved_2 = F.relu(self.conv_2(embedded).squeeze(3))\n",
    "        \n",
    "        # conved_n = [batch_size, n_filters, sentence_length - filter_sizes[n] + 1]\n",
    "        \n",
    "        pooled_0 = F.max_pool1d(conved_0, conved_0.shape[2]).squeeze(2)\n",
    "        pooled_1 = F.max_pool1d(conved_1, conved_1.shape[2]).squeeze(2)\n",
    "        pooled_2 = F.max_pool1d(conved_2, conved_2.shape[2]).squeeze(2)\n",
    "        \n",
    "        # pooled_n = [batch_size, n_filters]\n",
    "        \n",
    "        cat = self.dropout(torch.cat((pooled_0, pooled_1, pooled_2), dim = 1))\n",
    "        \n",
    "        # cat = [batch_size, n_filters * len(filter_sizes)]\n",
    "        \n",
    "        return self.fc(cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56333a28",
   "metadata": {},
   "source": [
    "Currently the `CNN` model can only use 3 different-sized filters, but we can actually improve the code of our model to make it mode generic and take any number of filters.\n",
    "<br>\n",
    "\n",
    "We do this by placing all of convolutional layers in a `nn.ModuleList`, a function used to hold a list of PyTorch `nn.Module`s. If we simply used a standard Python list, the modules within the list cannot be \"seen\" by any modules outside the list which will cause some errors.\n",
    "<br>\n",
    "\n",
    "We can now pass an arbitray-sized list of filter sizes and the list comprehension will create a convolutional layer for each of them. Then, in the `forward` method we iterate through the list applying each convolutional layer to get a a list of convolutional outputs, which we also feed through the max pooling in a list comprehension before concatenating together and passing through the dropout and linear layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "adaba226",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, \n",
    "                output_dim, dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        \n",
    "        self.convs = nn.ModuleList([\n",
    "                                    nn.Conv2d(in_channels = 1,\n",
    "                                             out_channels = n_filters,\n",
    "                                             kernel_size = (fs, embedding_dim)\n",
    "                                             )\n",
    "                                    for fs in filter_sizes\n",
    "                                ])\n",
    "        \n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        \n",
    "        # text = [batch_size, sentence_length]\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "        \n",
    "        #embedded = [batch_size, sentence_length, emb_dim]\n",
    "        \n",
    "        embedded = embedded.unsqueeze(1)\n",
    "        \n",
    "        # embedded = [batch_size, 1, sentence_length, embed_dim]\n",
    "        \n",
    "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
    "        \n",
    "        # conved_n = [batch_sizes, n_filters, sentence_length - filter_sizes[n] + 1]\n",
    "        \n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "#         pooled_0 = F.max_pool1d(conved[0], conved[0].shape[2]).squeeze(2)\n",
    "#         pooled_1 = F.max_pool1d(conved[1], conved[1].shape[2]).squeeze(2)\n",
    "#         pooled_2 = F.max_pool1d(conved[2], conved[2].shape[2]).squeeze(2)\n",
    "        \n",
    "        # pooled_n = [batch_size, n_fiters]\n",
    "        \n",
    "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
    "        \n",
    "        # cat = [batch_size, n_filters * len(filter_sizes)]\n",
    "        \n",
    "        return self.fc(cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dd90d0",
   "metadata": {},
   "source": [
    "We can also implement the above model using 1-dimensional convolutional layers, where the embedding dimension is the \"depth\" of the filter and the number of tokens in the sentence is the width.\n",
    "<br> \n",
    "\n",
    "We'll run our texts in this notebook using the 2-dimensional convolutional model, but leave the implementation for the 1-dimensional model below for anyone interested.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95bd316e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN1d(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, \n",
    "                output_dim, dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "                \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        \n",
    "        self.convs = nn.ModuleList([\n",
    "                                    nn.Conv1d(in_channels = embedding_dim,\n",
    "                                             out_channels = n_filters,\n",
    "                                             kernel_size = fs)\n",
    "                                    for fs in filter_sizes\n",
    "                                ])\n",
    "        \n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        \n",
    "        # text = [batch_size, sentence_length]\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "        \n",
    "        # embedded = [batch_size, sentence_length, embed_dim]\n",
    "        \n",
    "        embedded = embedded.permute(0, 2, 1)\n",
    "        \n",
    "        # embedded = [batch_size, embed_dim, sentence_length]\n",
    "        \n",
    "        conved = [F.relu(conv(embedded)) for conv in self.convs]\n",
    "        \n",
    "        # conved_n = [batch_size, n_filters, sentence_length - filter_size[n] + 1]\n",
    "        \n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        \n",
    "        # pooled_n = [batch_size, n_filters]\n",
    "        \n",
    "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
    "        \n",
    "        # cat = [batch_size, n_filters * len(filter_sizes)]\n",
    "        \n",
    "        return self.fc(cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94663903",
   "metadata": {},
   "source": [
    "We create an instance of our `CNN` class.\n",
    "<br> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d832be52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
    "                 bidirectional, dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        \n",
    "        self.rnn = nn.LSTM(embedding_dim, \n",
    "                           hidden_dim, \n",
    "                           num_layers=n_layers, \n",
    "                           bidirectional=bidirectional, \n",
    "                           dropout=dropout)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text, text_lengths):\n",
    "        \n",
    "        #text = [sent len, batch size]\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "        \n",
    "        #embedded = [sent len, batch size, emb dim]\n",
    "        \n",
    "        #pack sequence\n",
    "        # lengths need to be on CPU!\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.to('cpu'))\n",
    "        \n",
    "        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n",
    "        \n",
    "        #unpack sequence\n",
    "        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
    "\n",
    "        #output = [sent len, batch size, hid dim * num directions]\n",
    "        #output over padding tokens are zero tensors\n",
    "        \n",
    "        #hidden = [num layers * num directions, batch size, hid dim]\n",
    "        #cell = [num layers * num directions, batch size, hid dim]\n",
    "        \n",
    "        #concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n",
    "        #and apply dropout\n",
    "        \n",
    "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
    "                \n",
    "        #hidden = [batch size, hid dim * num directions]\n",
    "            \n",
    "        return self.fc(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1f723bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (embedding): Embedding(29703, 100, padding_idx=1)\n",
      "  (rnn): LSTM(100, 256, num_layers=2, dropout=0.5, bidirectional=True)\n",
      "  (fc): Linear(in_features=512, out_features=3, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 3\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.5\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "model = RNN(INPUT_DIM, \n",
    "            EMBEDDING_DIM, \n",
    "            HIDDEN_DIM, \n",
    "            OUTPUT_DIM, \n",
    "            N_LAYERS, \n",
    "            BIDIRECTIONAL, \n",
    "            DROPOUT, \n",
    "            PAD_IDX)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "010653c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT_DIM = len(TEXT.vocab)\n",
    "# EMBEDDING_DIM = 100\n",
    "# N_FILTERS = 100\n",
    "# FILTER_SIZES = [3,4,5]\n",
    "# OUTPUT_DIM = 3\n",
    "# DROPOUT = 0.5\n",
    "# PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "# model = CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71491fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 5,281,983 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76d6f2a",
   "metadata": {},
   "source": [
    "Load the pre-trained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce1a17d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1117, -0.4966,  0.1631,  ...,  1.2647, -0.2753, -0.1325],\n",
       "        [-0.8555, -0.7208,  1.3755,  ...,  0.0825, -1.1314,  0.3997],\n",
       "        [ 0.0085,  0.1802,  0.7703,  ...,  0.2993,  0.4085,  0.4761],\n",
       "        ...,\n",
       "        [-0.5832, -0.5807,  0.3504,  ...,  0.4043, -0.0192,  0.0945],\n",
       "        [ 1.7948, -0.4856,  0.3013,  ..., -0.8426, -0.8726,  0.2949],\n",
       "        [ 0.1527, -1.0775, -0.2867,  ..., -0.4466, -0.5326, -1.3527]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1c6b1f",
   "metadata": {},
   "source": [
    "Then zero the initial weights of the unknown and padding tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "778e8375",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "\n",
    "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fbd3c9",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "\n",
    "We first have to initialize the optimizer, loss function (criterion) and place the model and criterion on the GPU (if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "605294b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5bbf12",
   "metadata": {},
   "source": [
    "We define a function for training our model...\n",
    "\n",
    "**Note**: As dropout is used, it is always advisable to use `model.train()` to ensure the dropout is \"turned on\" while training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "313f5f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    loop = tqdm(iterator)\n",
    "    \n",
    "    for batch in loop:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        text, text_lengths = batch.message\n",
    "        \n",
    "        predictions = model.forward(text, text_lengths).squeeze(1)\n",
    "#         print(predictions.argmax())\n",
    "        loss = criterion(predictions, batch.label)\n",
    "        \n",
    "        acc = (predictions.argmax() == batch.label).sum()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ac49f6",
   "metadata": {},
   "source": [
    "We define a function for testing our model...\n",
    "\n",
    "**Note**: Again, since dropout is used, `model.eval()` must be called to ensure the dropout is \"turned off\" while evaluating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2aa3b23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for batch in iterator:\n",
    "            \n",
    "            text, text_lengths = batch.message\n",
    "            \n",
    "            predictions = model(text, text_lengths).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, batch.label)\n",
    "            \n",
    "            acc = (predictions.argmax() == batch.label).sum()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcd88c5",
   "metadata": {},
   "source": [
    "Let's define our function to tell us how long epochs take."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "49b7b31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    \n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559786d0",
   "metadata": {},
   "source": [
    "Finally, we train our model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "72fb3678",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 557/557 [02:27<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 2m 30s\n",
      "\tTrain Loss: 0.880 | Train Acc: 19.21%\n",
      "\t Val. Loss: 0.798 |  Val. Acc: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 557/557 [02:28<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Epoch Time: 2m 31s\n",
      "\tTrain Loss: 0.798 | Train Acc: 48.47%\n",
      "\t Val. Loss: 0.769 |  Val. Acc: 41.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 557/557 [02:24<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Epoch Time: 2m 27s\n",
      "\tTrain Loss: 0.748 | Train Acc: 53.14%\n",
      "\t Val. Loss: 0.754 |  Val. Acc: 17.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 557/557 [02:35<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Epoch Time: 2m 39s\n",
      "\tTrain Loss: 0.709 | Train Acc: 26.39%\n",
      "\t Val. Loss: 0.744 |  Val. Acc: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 557/557 [02:42<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Epoch Time: 2m 45s\n",
      "\tTrain Loss: 0.670 | Train Acc: 26.75%\n",
      "\t Val. Loss: 0.760 |  Val. Acc: 0.00%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 5\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), \"models/cnn-model.pt\")\n",
    "        \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "25b7cb8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.757 | Test Acc: 29.03%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.load_state_dict(torch.load('models/cnn-model.pt'))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57eb6df1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
